{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'documents': {'doc1': 'Paris is the capital of France. It is known for its iconic landmarks...',\n",
       "  'doc2': 'Photosynthesis is the process by which green plants and some other organisms...',\n",
       "  'doc3': 'Python is a high-level, interpreted programming language known for its simplicity...'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"queries\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"query\": \"What is the capital of France?\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"query\": \"How does photosynthesis work?\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"query\": \"Python programming language features\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "{\n",
    "  \"documents\": {\n",
    "    \"doc1\": \"Paris is the capital of France. It is known for its iconic landmarks...\",\n",
    "    \"doc2\": \"Photosynthesis is the process by which green plants and some other organisms...\",\n",
    "    \"doc3\": \"Python is a high-level, interpreted programming language known for its simplicity...\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query ID: 1, Query Text: The patient has KRAS mutation\n",
      "Rank 1: Document ID: doc1, Similarity: 0.8575\n",
      "Document Text: The trial includes patients with KRAS mutation\n",
      "\n",
      "Rank 2: Document ID: doc4, Similarity: 0.8360\n",
      "Document Text: The trial includes patients with BRAC mutation\n",
      "\n",
      "Rank 3: Document ID: doc3, Similarity: 0.7601\n",
      "Document Text: The trial excludes patients with a history of heart disease\n",
      "\n",
      "Rank 4: Document ID: doc6, Similarity: 0.7236\n",
      "Document Text: The trial excludes patients with pregnancy\n",
      "\n",
      "Rank 5: Document ID: doc5, Similarity: 0.7217\n",
      "Document Text: The triale excludes patients with HIV\n",
      "\n",
      "Rank 6: Document ID: doc7, Similarity: 0.7105\n",
      "Document Text: The trial includes patients undegoing radiotherapy\n",
      "\n",
      "Rank 7: Document ID: doc2, Similarity: 0.6666\n",
      "Document Text: The trial includes patients over 18 years of age\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_text(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    embeddings = output.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "def get_cosine_similarity(query_embedding, doc_embedding):\n",
    "    sim = cosine_similarity(query_embedding, doc_embedding)\n",
    "    return sim[0][0]\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def retrieve_best_matches(query, documents):\n",
    "    query_embedding = embed_text(query)\n",
    "\n",
    "    best_matches = []\n",
    "    for doc_id, doc_text in documents.items():\n",
    "        doc_embedding = embed_text(doc_text)\n",
    "        similarity = get_cosine_similarity(query_embedding, doc_embedding)\n",
    "        best_matches.append((doc_id, similarity))\n",
    "\n",
    "    best_matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return best_matches\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load Queries JSON\n",
    "    queries_path = \"queries.json\"\n",
    "    queries_data = load_json(queries_path)[\"queries\"]\n",
    "\n",
    "    # Load Documents JSON\n",
    "    documents_path = \"documents.json\"\n",
    "    documents_data = load_json(documents_path)[\"documents\"]\n",
    "\n",
    "    # Perform retrieval for each query\n",
    "    for query_entry in queries_data:\n",
    "        query_id = query_entry[\"id\"]\n",
    "        query_text = query_entry[\"query\"]\n",
    "\n",
    "        # Retrieve best matches\n",
    "        matches = retrieve_best_matches(query_text, documents_data)\n",
    "        # Print ranked list of matches for each query\n",
    "        print(f\"\\nQuery ID: {query_id}, Query Text: {query_text}\")\n",
    "        for rank, (doc_id, similarity) in enumerate(matches):\n",
    "            print(f\"Rank {rank + 1}: Document ID: {doc_id}, Similarity: {similarity:.4f}\")\n",
    "            print(f\"Document Text: {documents_data[doc_id]}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
